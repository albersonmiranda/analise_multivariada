---
title: Métodos Multivariados de Análise de Dados
subtitle: 2ª Atividade
author: Alberson da Silva Miranda
date: last-modified
date-format: long
lang: pt-BR
thanks: Código disponível em https://github.com/albersonmiranda/analise_multivariada.
toc: true
number-sections: true
sansfont: Liberation Serif
mainfont: Liberation Serif
monofont: Fira Code
monofontoptions:
  - Scale=0.8
highlight-style: zenburn
code-line-numbers: true
format:
  pdf:
    documentclass: scrreprt
    header-includes: 
      - \renewcommand\thesubsection{\alph{subsection}}
---

```{r setup, include=FALSE}
# set seed
set.seed(100)
```

# INTRODUÇÃO

A atividade consiste na classificação de municípios do Espírito Santo em relação à transparência. O *dataset* é composto por 6 variáveis:

- `ID_PCP`: Índice de divulgação dos Procedimentos Contábeis Patrimoniais;
- `ITGP`: Índice de Transparência e Governança Pública;
- `LEG`: Dimensão Legislativa;
- `PLAT`: Dimensão Plataformas;
- `AG`: Dimensão Administrativo e Governança;
- `TFO`: Dimensão Transparência Financeira Orçamentária;
- `CEP`: Dimensão Comunicação, Engajamento e Participação Social.

E a variável resposta `Classificação` tem os valores 1, 2 e 3, que representam as classificações `Ótimo`, `Regular` e `Ruim`, respectivamente.

# IMPORTAÇÃO DOS DADOS

```{r}
# importando dados
dados <- readxl::read_excel(
  "data-raw/analise_discriminante/transparencia.xlsx",
  sheet = "ID_PCP_2021"
)

# corrigindo nome das colunas
dados <- janitor::clean_names(dados)

# corrigindo formatos
dados$classificacao <- factor(
  dados$classificacao,
  levels = 1:3,
  labels = c("Ótimo", "Regular", "Ruim"),
  ordered = TRUE
)

print(dados)
```

# MODELAGEM

Utilizaremos o *framework* {mlr3} para realizar toda a esteira de modelagem.

```{r}
# metapacote
library(mlr3verse)

# criação da tarefa
task <- TaskClassif$new(
  id = "transparencia",
  backend = dados[, !names(dados) %in% "municipio"],
  target = "classificacao"
)

# split em treino e teste (80%/20%)
ids <- partition(task, ratio = 0.8)

# pipeline
pipeline <- po(
  # normalização das variáveis numéricas
  "scale",
  # média zero
  center = TRUE,
  # desvio padrão unitário
  scale = TRUE
) %>>%
  # linear discriminant analysis
  po("learner", lrn("classif.lda"))

# convertendo para learner
learner <- as_learner(pipeline)

# treinamento
learner$train(task, row_ids = ids$train)

# modelo
print(learner$model)
```

Com o modelo treinado, vamos realizar a predição.

```{r}
# predição
preds <- learner$predict(task, row_ids = ids$test)
as.data.table(preds)
```

E, por fim, a avaliação do modelo.

```{r}
# matriz de confusão
confusao <- table(preds$data$truth, preds$data$response)

# acurácia
acuracia <- sum(diag(confusao) / sum(confusao))

# precisão
precisao <- diag(confusao) / colSums(confusao)

# recall
recall <- diag(confusao) / rowSums(confusao)

# métricas
confusao
acuracia
precisao
recall
```

Como resultado, o modelo se mostrou muito eficiente, com acurácia de 94%, tendo errado apenas uma observação, classificando como `Regular` um município de *actual* `Ruim`. Isso significa uma precisão de 100% nas classes `Ótimo` e `Ruim`, e 91% na classe `Regular`, e recall de 100% nas classes `Ótimo` e `Regular`, e 67% na classe `Ruim`.